# Generative Models for Image-to-Image Translation and Generation

This repository contains implementations of different **deep generative models** for both image generation and image-to-image translation tasks. The work explores Variational Autoencoders (VAE), multiple types of GANs, and translation frameworks such as Conditional GANs (cGAN) and CycleGAN.

All code is written inside a single **Jupyter Notebook**: **`main.ipynb`**, including preprocessing, model architectures, training, evaluation, visualizations, a **Streamlit interface**, and an **ngrok cell** for generating a public demo link.

---

## ğŸ“Œ Implemented Tasks

### 1. Signature Image Generation (VAE + Simple GAN)

* **VAE**: Learns latent representations of signature images using convolutional encoders/decoders.
* **Simple GAN**: Generates fake signatures from random noise.
* **Dataset**: Grayscale signature images resized to **64Ã—64**.
* **Augmentation**: Scaling, rotation, and noise addition to handle the small dataset size.

---

### 2. Custom GAN on CIFAR-10 (Cats & Dogs Only)

* **Generator**: DCGAN-style network producing **32Ã—32 RGB images**.
* **Discriminator**: **Siamese-style**, comparing real vs. generated images and returning a similarity score.
* **Dataset**: CIFAR-10, filtered for cats and dogs, normalized to `[-1, 1]`.

---

### 3. Conditional GAN (cGAN) â€“ Sketch to Face

* Generator takes a **sketch + noise** and outputs a realistic face.
* Discriminator evaluates **(sketch, face)** pairs.
* **Dataset**: Person Face Sketches dataset with paired **sketch-photo** images (64Ã—64).

---

### 4. CycleGAN â€“ Face â†” Sketch Translation

* **Two Generators**: Face â†’ Sketch and Sketch â†’ Face.
* **Two PatchGAN Discriminators** for patch realism.
* Uses **adversarial + cycle consistency + identity losses**.
* Bidirectional translation achieved reliably with longer training.
* Models are checkpointed after every epoch.

---

## âš™ï¸ Training Setup

* **Optimizer**: Adam (lr = 0.0002, betas = (0.5, 0.999))
* **Augmentation**: Scaling, rotation, noise injection (signatures).
* **Checkpoints**: Saved every epoch.
* **Environment**: Notebook tested on Kaggle T4 GPU.

---

## ğŸ“Š Results Summary

* **VAE & GAN**:

  * VAE reconstructs signatures well.
  * GAN signatures improve visually with training.

* **Custom GAN (Cats & Dogs)**:

  * Siamese discriminator improves realism.
  * Cat/dog features emerge clearly after training.

* **cGAN**:

  * Blurry faces at first, clearer with more epochs.

* **CycleGAN**:

  * Reliable face â†” sketch translation.
  * Better detail with longer training.

---

## â–¶ï¸ Running the Project

Clone and install requirements:

```bash
git clone <repo-link>
cd <repo-name>
```

Open the notebook in Jupyter, Colab, or Kaggle (with T4 GPU enabled):

```bash
jupyter notebook main.ipynb
```

Run the cells sequentially to preprocess data, train and test the models, and view the evaluations.

### Streamlit + ngrok Demo

A **Streamlit app** is included at the end for the fourth task. Running only that cell will launch the demo:

with **ngrok**:

```bash
!ngrok authtoken <your_token>
!streamlit run streamlit_app.py --server.port 8000
```

A public link will be generated automatically.

---

## ğŸ“‚ File Structure

```
main.ipynb
 â”œâ”€â”€ Data preprocessing & augmentation
 â”œâ”€â”€ VAE & Simple GAN (signatures)
 â”œâ”€â”€ Custom GAN (CIFAR-10 cats/dogs)
 â”œâ”€â”€ cGAN (sketch â†’ face)
 â”œâ”€â”€ CycleGAN (face â†” sketch)
 â”œâ”€â”€ Training, evaluation, plots
 â””â”€â”€ Streamlit interface + ngrok cell
```

---

## ğŸ”‘ Insights

* Data augmentation is critical for limited datasets.
* Siamese discriminators give more structured feedback than plain real/fake.
* Stable cGAN/CycleGAN training requires balancing adversarial, cycle, and identity losses.
* CycleGAN enables **unpaired** translation but is resource heavy.

---

## ğŸ“‚ Datasets Used

* [Signature Verification Dataset]

   â„¹ï¸ Kaggle link: (https://www.kaggle.com/datasets/robinreni/signature-verification-dataset)

* [CIFAR-10 â€” A classic dataset consisting of 60,000 32Ã—32 color images in 10 classes (50,000 train + 10,000 test)]

   â„¹ï¸ Download & info: (https://www.cs.toronto.edu/~kriz/cifar.html)

* [Person Face Sketches â€” Dataset of paired face photos and sketches (21,000+ images)]

   â„¹ï¸ Kaggle link: (https://www.kaggle.com/datasets/almightyj/person-face-sketches)

---

## ğŸ“– References

* Kingma & Welling, *Auto-Encoding Variational Bayes* (2013)
* Goodfellow et al., *Generative Adversarial Nets* (2014)
* Mirza & Osindero, *Conditional GANs* (2014)
* Zhu et al., *CycleGAN* (2017)
* Radford et al., *DCGAN* (2015)

---

âœï¸ **Author**: Abdulmoiz

---
